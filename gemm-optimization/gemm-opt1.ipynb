{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71272b80-58e1-4638-be26-f248f5116b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "import tvm.testing\n",
    "from tvm import te\n",
    "import numpy\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b10b78d-3927-4bc9-bd67-3c0354d59a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The size of the matrix\n",
    "# (M, K) x (K, N)\n",
    "# You are free to try out different shapes, sometimes TVM optimization outperforms numpy with MKL.\n",
    "M = 1024\n",
    "K = 1024\n",
    "N = 1024\n",
    "\n",
    "# The default tensor type in tvm\n",
    "dtype = \"float32\"\n",
    "\n",
    "# using Intel AVX2(Advanced Vector Extensions) ISA for SIMD\n",
    "# To get the best performance, please change the following line\n",
    "# to llvm -mcpu=core-avx2, or specific type of CPU you use\n",
    "target = \"llvm\"\n",
    "dev = tvm.device(target, 0)\n",
    "\n",
    "# Random generated tensor for testing\n",
    "a = tvm.nd.array(numpy.random.rand(M, K).astype(dtype), dev)\n",
    "b = tvm.nd.array(numpy.random.rand(K, N).astype(dtype), dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18cd2dd5-0c88-47c4-82f7-acbc7beb7e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy running time: 0.001303\n"
     ]
    }
   ],
   "source": [
    "# 学习如何用numpy来解决这个问题。\n",
    "np_repeat = 100\n",
    "np_runing_time = timeit.timeit(\n",
    "    setup=\"import numpy\\n\"\n",
    "    \"M = \" + str(M) + \"\\n\"\n",
    "    \"K = \" + str(K) + \"\\n\"\n",
    "    \"N = \" + str(N) + \"\\n\"\n",
    "    'dtype = \"float32\"\\n'\n",
    "    \"a = numpy.random.rand(M, K).astype(dtype)\\n\"\n",
    "    \"b = numpy.random.rand(K, N).astype(dtype)\\n\",\n",
    "    stmt=\"answer = numpy.dot(a, b)\",\n",
    "    number=np_repeat,\n",
    ")\n",
    "print(\"Numpy running time: %f\" % (np_runing_time / np_repeat))\n",
    "\n",
    "answer = numpy.dot(a.numpy(), b.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8150cde-0f82-4649-be24-87372e8c27f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 3.455440\n",
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(A: T.Buffer((1024, 1024), \"float32\"), B: T.Buffer((1024, 1024), \"float32\"), C: T.Buffer((1024, 1024), \"float32\")):\n",
      "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
      "        for m, n in T.grid(1024, 1024):\n",
      "            C_1 = T.Buffer((1048576,), data=C.data)\n",
      "            C_1[m * 1024 + n] = T.float32(0.0)\n",
      "            for k in range(1024):\n",
      "                cse_var_2: T.int32 = m * 1024\n",
      "                cse_var_1: T.int32 = cse_var_2 + n\n",
      "                A_1 = T.Buffer((1048576,), data=A.data)\n",
      "                B_1 = T.Buffer((1048576,), data=B.data)\n",
      "                C_1[cse_var_1] = C_1[cse_var_1] + A_1[cse_var_2 + k] * B_1[k * 1024 + n]\n"
     ]
    }
   ],
   "source": [
    "# Algorithm\n",
    "# 标准的tvm的写法\n",
    "k = te.reduce_axis((0, K), \"k\")\n",
    "A = te.placeholder((M, K), name=\"A\")\n",
    "B = te.placeholder((K, N), name=\"B\")\n",
    "C = te.compute((M, N), lambda m, n: te.sum(A[m, k] * B[k, n], axis=k), name=\"C\")\n",
    "\n",
    "# Default schedule\n",
    "s = te.create_schedule(C.op)\n",
    "func = tvm.build(s, [A, B, C], target=target, name=\"mmult\")\n",
    "assert func\n",
    "\n",
    "c = tvm.nd.array(numpy.zeros((M, N), dtype=dtype), dev)\n",
    "func(a, b, c)\n",
    "tvm.testing.assert_allclose(c.numpy(), answer, rtol=1e-5)\n",
    "\n",
    "evaluator = func.time_evaluator(func.entry_name, dev, number=1)\n",
    "print(\"Baseline: %f\" % evaluator(a, b, c).mean)\n",
    "\n",
    "print(tvm.lower(s, [A, B, C], simple_mode=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d383927-64b2-4652-bf0c-130a981d8677",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = 32\n",
    "kfactor = 4\n",
    "s = te.create_schedule(C.op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "646c9df1-1bd3-46ec-be78-6a00f5cc3089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blocking by loop tiling\n",
    "mo, no, mi, ni = s[C].tile(C.op.axis[0], C.op.axis[1], bn, bn)\n",
    "(kaxis,) = s[C].op.reduce_axis\n",
    "ko, ki = s[C].split(kaxis, factor=kfactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7027e2da-b5c7-4c7e-9869-ed55684b04ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(A: T.Buffer((1024, 1024), \"float32\"), B: T.Buffer((1024, 1024), \"float32\"), C: T.Buffer((1024, 1024), \"float32\")):\n",
      "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
      "        for m_outer, n_outer, m_inner, n_inner in T.grid(32, 32, 32, 32):\n",
      "            C_1 = T.Buffer((1048576,), data=C.data)\n",
      "            C_1[m_outer * 32768 + m_inner * 1024 + n_outer * 32 + n_inner] = T.float32(0.0)\n",
      "            for k_outer, k_inner in T.grid(256, 4):\n",
      "                cse_var_3: T.int32 = n_outer * 32\n",
      "                cse_var_2: T.int32 = m_outer * 32768 + m_inner * 1024\n",
      "                cse_var_1: T.int32 = cse_var_2 + cse_var_3 + n_inner\n",
      "                A_1 = T.Buffer((1048576,), data=A.data)\n",
      "                B_1 = T.Buffer((1048576,), data=B.data)\n",
      "                C_1[cse_var_1] = C_1[cse_var_1] + A_1[cse_var_2 + k_outer * 4 + k_inner] * B_1[k_outer * 4096 + k_inner * 1024 + cse_var_3 + n_inner]\n"
     ]
    }
   ],
   "source": [
    "print(tvm.lower(s, [A, B, C], simple_mode=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5b3fb2b-78a3-4e5a-ab38-1a6baa54860d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hoist reduction domain outside the blocking loop\n",
    "s[C].reorder(mo, no, ko, ki, mi, ni)\n",
    "\n",
    "# 一个cache是32所以要reorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd506c2a-f329-4f23-b220-2a90160da624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(A: T.Buffer((1024, 1024), \"float32\"), B: T.Buffer((1024, 1024), \"float32\"), C: T.Buffer((1024, 1024), \"float32\")):\n",
      "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
      "        for m_outer, n_outer in T.grid(32, 32):\n",
      "            C_1 = T.Buffer((1048576,), data=C.data)\n",
      "            for m_inner_init, n_inner_init in T.grid(32, 32):\n",
      "                C_1[m_outer * 32768 + m_inner_init * 1024 + n_outer * 32 + n_inner_init] = T.float32(0.0)\n",
      "            for k_outer, k_inner, m_inner, n_inner in T.grid(256, 4, 32, 32):\n",
      "                cse_var_3: T.int32 = n_outer * 32\n",
      "                cse_var_2: T.int32 = m_outer * 32768 + m_inner * 1024\n",
      "                cse_var_1: T.int32 = cse_var_2 + cse_var_3 + n_inner\n",
      "                A_1 = T.Buffer((1048576,), data=A.data)\n",
      "                B_1 = T.Buffer((1048576,), data=B.data)\n",
      "                C_1[cse_var_1] = C_1[cse_var_1] + A_1[cse_var_2 + k_outer * 4 + k_inner] * B_1[k_outer * 4096 + k_inner * 1024 + cse_var_3 + n_inner]\n"
     ]
    }
   ],
   "source": [
    "print(tvm.lower(s, [A, B, C], simple_mode=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "074c9f45-7c9a-48aa-94c2-e88392b116b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opt1: 0.208868\n"
     ]
    }
   ],
   "source": [
    "func = tvm.build(s, [A, B, C], target=target, name=\"mmult\")\n",
    "assert func\n",
    "\n",
    "c = tvm.nd.array(numpy.zeros((M, N), dtype=dtype), dev)\n",
    "func(a, b, c)\n",
    "tvm.testing.assert_allclose(c.numpy(), answer, rtol=1e-5)\n",
    "\n",
    "# By simply tiling the loop 32x32, and hoisting ko, ki outside the blocking loops,\n",
    "# we can see big speedup compared with the baseline.\n",
    "evaluator = func.time_evaluator(func.entry_name, dev, number=10)\n",
    "print(\"Opt1: %f\" % evaluator(a, b, c).mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89d82e88-cd60-47ec-ade6-4b9bbb89d822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(A: T.Buffer((1024, 1024), \"float32\"), B: T.Buffer((1024, 1024), \"float32\"), C: T.Buffer((1024, 1024), \"float32\")):\n",
      "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
      "        for m_outer, n_outer in T.grid(32, 32):\n",
      "            C_1 = T.Buffer((1048576,), data=C.data)\n",
      "            for m_inner_init, n_inner_init in T.grid(32, 32):\n",
      "                C_1[m_outer * 32768 + m_inner_init * 1024 + n_outer * 32 + n_inner_init] = T.float32(0.0)\n",
      "            for k_outer, k_inner, m_inner, n_inner in T.grid(256, 4, 32, 32):\n",
      "                cse_var_3: T.int32 = n_outer * 32\n",
      "                cse_var_2: T.int32 = m_outer * 32768 + m_inner * 1024\n",
      "                cse_var_1: T.int32 = cse_var_2 + cse_var_3 + n_inner\n",
      "                A_1 = T.Buffer((1048576,), data=A.data)\n",
      "                B_1 = T.Buffer((1048576,), data=B.data)\n",
      "                C_1[cse_var_1] = C_1[cse_var_1] + A_1[cse_var_2 + k_outer * 4 + k_inner] * B_1[k_outer * 4096 + k_inner * 1024 + cse_var_3 + n_inner]\n"
     ]
    }
   ],
   "source": [
    "print(tvm.lower(s, [A, B, C], simple_mode=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f703482e-883a-4f9b-ac37-90431cffcf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opt2: 0.223579\n"
     ]
    }
   ],
   "source": [
    "s = te.create_schedule(C.op)\n",
    "mo, no, mi, ni = s[C].tile(C.op.axis[0], C.op.axis[1], bn, bn)\n",
    "(kaxis,) = s[C].op.reduce_axis\n",
    "ko, ki = s[C].split(kaxis, factor=kfactor)\n",
    "\n",
    "s[C].reorder(mo, no, ko, ki, mi, ni)\n",
    "\n",
    "# Vectorization\n",
    "s[C].vectorize(ni)\n",
    "\n",
    "func = tvm.build(s, [A, B, C], target=target, name=\"mmult\")\n",
    "assert func\n",
    "\n",
    "c = tvm.nd.array(numpy.zeros((M, N), dtype=dtype), dev)\n",
    "func(a, b, c)\n",
    "tvm.testing.assert_allclose(c.numpy(), answer, rtol=1e-5)\n",
    "\n",
    "evaluator = func.time_evaluator(func.entry_name, dev, number=10)\n",
    "print(\"Opt2: %f\" % evaluator(a, b, c).mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30229d1f-1e8f-422d-bffa-1e49254046cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(A: T.Buffer((1024, 1024), \"float32\"), B: T.Buffer((1024, 1024), \"float32\"), C: T.Buffer((1024, 1024), \"float32\")):\n",
      "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
      "        for m_outer, n_outer in T.grid(32, 32):\n",
      "            C_1 = T.Buffer((1048576,), data=C.data)\n",
      "            for m_inner_init in range(32):\n",
      "                C_1[m_outer * 32768 + m_inner_init * 1024 + n_outer * 32:m_outer * 32768 + m_inner_init * 1024 + n_outer * 32 + 32] = T.Broadcast(T.float32(0.0), 32)\n",
      "            for k_outer, k_inner, m_inner in T.grid(256, 4, 32):\n",
      "                cse_var_3: T.int32 = n_outer * 32\n",
      "                cse_var_2: T.int32 = m_outer * 32768 + m_inner * 1024\n",
      "                cse_var_1: T.int32 = cse_var_2 + cse_var_3\n",
      "                A_1 = T.Buffer((1048576,), data=A.data)\n",
      "                B_1 = T.Buffer((1048576,), data=B.data)\n",
      "                C_1[cse_var_1:cse_var_1 + 32] = C_1[cse_var_1:cse_var_1 + 32] + T.Broadcast(A_1[cse_var_2 + k_outer * 4 + k_inner], 32) * B_1[k_outer * 4096 + k_inner * 1024 + cse_var_3:k_outer * 4096 + k_inner * 1024 + cse_var_3 + 32]\n"
     ]
    }
   ],
   "source": [
    "print(tvm.lower(s, [A, B, C], simple_mode=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3c141b9-c2e3-49a1-ae56-3625c8d36f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opt3: 0.111549\n"
     ]
    }
   ],
   "source": [
    "s = te.create_schedule(C.op)\n",
    "mo, no, mi, ni = s[C].tile(C.op.axis[0], C.op.axis[1], bn, bn)\n",
    "(kaxis,) = s[C].op.reduce_axis\n",
    "ko, ki = s[C].split(kaxis, factor=kfactor)\n",
    "\n",
    "# re-ordering\n",
    "s[C].reorder(mo, no, ko, mi, ki, ni)\n",
    "s[C].vectorize(ni)\n",
    "\n",
    "func = tvm.build(s, [A, B, C], target=target, name=\"mmult\")\n",
    "assert func\n",
    "\n",
    "c = tvm.nd.array(numpy.zeros((M, N), dtype=dtype), dev)\n",
    "func(a, b, c)\n",
    "tvm.testing.assert_allclose(c.numpy(), answer, rtol=1e-5)\n",
    "\n",
    "evaluator = func.time_evaluator(func.entry_name, dev, number=10)\n",
    "print(\"Opt3: %f\" % evaluator(a, b, c).mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b2bb29b-f6a1-4a8b-a3bc-37af065b3be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opt4: 0.124942\n"
     ]
    }
   ],
   "source": [
    "# We have to re-write the algorithm slightly.\n",
    "# We have to re-write the algorithm slightly.\n",
    "packedB = te.compute(\n",
    "    (N / bn, K, bn), lambda bigN, k, littleN: B[k, bigN * bn + littleN], name=\"packedB\"\n",
    ")\n",
    "C = te.compute(\n",
    "    (M, N),\n",
    "    lambda m, n: te.sum(A[m, k] * packedB[n // bn, k, tvm.tir.indexmod(n, bn)], axis=k),\n",
    "    name=\"C\",\n",
    ")\n",
    "\n",
    "s = te.create_schedule(C.op)\n",
    "\n",
    "mo, no, mi, ni = s[C].tile(C.op.axis[0], C.op.axis[1], bn, bn)\n",
    "(kaxis,) = s[C].op.reduce_axis\n",
    "ko, ki = s[C].split(kaxis, factor=kfactor)\n",
    "\n",
    "s[C].reorder(mo, no, ko, mi, ki, ni)\n",
    "s[C].vectorize(ni)\n",
    "\n",
    "bigN, _, littleN = s[packedB].op.axis\n",
    "s[packedB].vectorize(littleN)\n",
    "s[packedB].parallel(bigN)\n",
    "\n",
    "func = tvm.build(s, [A, B, C], target=target, name=\"mmult\")\n",
    "assert func\n",
    "\n",
    "c = tvm.nd.array(numpy.zeros((M, N), dtype=dtype), dev)\n",
    "func(a, b, c)\n",
    "tvm.testing.assert_allclose(c.numpy(), answer, rtol=1e-5)\n",
    "\n",
    "evaluator = func.time_evaluator(func.entry_name, dev, number=10)\n",
    "print(\"Opt4: %f\" % evaluator(a, b, c).mean)\n",
    "\n",
    "s = te.create_schedule(C.op)\n",
    "\n",
    "mo, no, mi, ni = s[C].tile(C.op.axis[0], C.op.axis[1], bn, bn)\n",
    "(kaxis,) = s[C].op.reduce_axis\n",
    "ko, ki = s[C].split(kaxis, factor=kfactor)\n",
    "\n",
    "s[C].reorder(mo, no, ko, mi, ki, ni)\n",
    "s[C].vectorize(ni)\n",
    "\n",
    "bigN, _, littleN = s[packedB].op.axis\n",
    "s[packedB].vectorize(littleN)\n",
    "s[packedB].parallel(bigN)\n",
    "\n",
    "func = tvm.build(s, [A, B, C], target=target, name=\"mmult\")\n",
    "assert func\n",
    "\n",
    "c = tvm.nd.array(numpy.zeros((M, N), dtype=dtype), dev)\n",
    "func(a, b, c)\n",
    "tvm.testing.assert_allclose(c.numpy(), answer, rtol=1e-5)\n",
    "\n",
    "evaluator = func.time_evaluator(func.entry_name, dev, number=10)\n",
    "print(\"Opt4: %f\" % evaluator(a, b, c).mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18492ccb-a88e-4e41-a32d-b0a5a9163198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opt5: 0.117523\n"
     ]
    }
   ],
   "source": [
    "s = te.create_schedule(C.op)\n",
    "\n",
    "# Allocate write cache\n",
    "CC = s.cache_write(C, \"global\")\n",
    "\n",
    "mo, no, mi, ni = s[C].tile(C.op.axis[0], C.op.axis[1], bn, bn)\n",
    "\n",
    "# Write cache is computed at no\n",
    "s[CC].compute_at(s[C], no)\n",
    "\n",
    "# New inner axes\n",
    "mc, nc = s[CC].op.axis\n",
    "\n",
    "(kaxis,) = s[CC].op.reduce_axis\n",
    "ko, ki = s[CC].split(kaxis, factor=kfactor)\n",
    "s[CC].reorder(ko, mc, ki, nc)\n",
    "s[CC].vectorize(nc)\n",
    "\n",
    "# TODO: Add separate optimization step to discuss loop unrolling\n",
    "# unrolling is a loop optimization strategy which can reduce branch\n",
    "# prediction failures and increases the chance of concurrent execution\n",
    "# unroll kfactor loops\n",
    "s[CC].unroll(ki)\n",
    "\n",
    "bigN, _, littleN = s[packedB].op.axis\n",
    "s[packedB].vectorize(littleN)\n",
    "s[packedB].parallel(bigN)\n",
    "\n",
    "func = tvm.build(s, [A, B, C], target=target, name=\"mmult\")\n",
    "assert func\n",
    "\n",
    "c = tvm.nd.array(numpy.zeros((M, N), dtype=dtype), dev)\n",
    "func(a, b, c)\n",
    "tvm.testing.assert_allclose(c.numpy(), answer, rtol=1e-5)\n",
    "\n",
    "evaluator = func.time_evaluator(func.entry_name, dev, number=10)\n",
    "print(\"Opt5: %f\" % evaluator(a, b, c).mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6f5ea57-bf96-4aed-bdb9-70b9d590c1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opt6: 0.005964\n"
     ]
    }
   ],
   "source": [
    "s = te.create_schedule(C.op)\n",
    "\n",
    "CC = s.cache_write(C, \"global\")\n",
    "\n",
    "mo, no, mi, ni = s[C].tile(C.op.axis[0], C.op.axis[1], bn, bn)\n",
    "\n",
    "s[CC].compute_at(s[C], no)\n",
    "\n",
    "mc, nc = s[CC].op.axis\n",
    "\n",
    "(kaxis,) = s[CC].op.reduce_axis\n",
    "ko, ki = s[CC].split(kaxis, factor=kfactor)\n",
    "s[CC].reorder(ko, mc, ki, nc)\n",
    "s[CC].vectorize(nc)\n",
    "s[CC].unroll(ki)\n",
    "\n",
    "# parallel\n",
    "s[C].parallel(mo)\n",
    "\n",
    "bigN, _, littleN = s[packedB].op.axis\n",
    "s[packedB].vectorize(littleN)\n",
    "s[packedB].parallel(bigN)\n",
    "\n",
    "func = tvm.build(s, [A, B, C], target=target, name=\"mmult\")\n",
    "assert func\n",
    "\n",
    "c = tvm.nd.array(numpy.zeros((M, N), dtype=dtype), dev)\n",
    "func(a, b, c)\n",
    "tvm.testing.assert_allclose(c.numpy(), answer, rtol=1e-5)\n",
    "\n",
    "evaluator = func.time_evaluator(func.entry_name, dev, number=50)\n",
    "opt6_time = evaluator(a, b, c).mean\n",
    "print(\"Opt6: %f\" % opt6_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d3e630-7b7a-44ed-9660-15ea7d4d4e29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
